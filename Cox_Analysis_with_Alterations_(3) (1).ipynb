{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "136c28f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "136c28f5",
        "outputId": "4c188136-4774-465f-9232-870f9dfe0b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lifelines\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.15.3)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from lifelines) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.8.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines)\n",
            "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (1.17.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
            "Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=55504828fc3bfe8366fe76ab9e4e345ae0e5bb2e713016ad6dd1e93ce11f1faa\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, autograd-gamma, formulaic, lifelines\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-1.1.1 interface-meta-1.3.0 lifelines-0.30.0\n"
          ]
        }
      ],
      "source": [
        "!pip install lifelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb9b9dbb",
      "metadata": {
        "id": "eb9b9dbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625511d4-0515-4745-9ad3-29bee93df88e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-f2b2cf153336>:5: DtypeWarning: Columns (150) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/sample_data/final_dataset_with_clinical (1).csv')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from lifelines import CoxPHFitter\n",
        "\n",
        "# Load the clinical dataset\n",
        "df = pd.read_csv('/content/sample_data/final_dataset_with_clinical (1).csv')\n",
        "# Load gene panel\n",
        "gene_panel = pd.read_excel('/content/sample_data/gene_panel_update.xlsx')\n",
        "gene_list = gene_panel.columns.tolist() if gene_panel.shape[1] > 1 else gene_panel.iloc[:, 0].dropna().unique().tolist()\n",
        "\n",
        "# Filter genes present in the dataset\n",
        "available_genes = [gene for gene in gene_list if gene in df.columns]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# List of genes want to check\n",
        "genes_to_check = ['AKT1', 'AXIN1', 'BRAF', 'CCND1', 'CDK6']\n",
        "\n",
        "# Loop through each gene and create a new _altered column\n",
        "for gene in genes_to_check:\n",
        "    if gene in df.columns:\n",
        "        df[gene + '_altered'] = df[gene].apply(lambda x: 1 if pd.notna(x) and str(x).strip().lower() != 'none' else 0)\n",
        "\n",
        "# Preview counts of alterations\n",
        "for gene in genes_to_check:\n",
        "    col = gene + '_altered'\n",
        "    if col in df.columns:\n",
        "        print(f\"{gene}: {df[col].sum()} alterations\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VwPBUc94FD4",
        "outputId": "0f7e25d3-cdbe-41db-d2fa-e23080cee6c7"
      },
      "id": "6VwPBUc94FD4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AKT1: 118 alterations\n",
            "BRAF: 667 alterations\n",
            "CCND1: 92 alterations\n",
            "CDK6: 58 alterations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d38e8f9e",
      "metadata": {
        "id": "d38e8f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30ec11c-78f5-45dd-f695-886f64441cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column AKT1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'AKT1_altered'].var())\n",
            ">>> print(df.loc[~events, 'AKT1_altered'].var())\n",
            "\n",
            "A very low variance means that the column AKT1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.124. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATM_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATM_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATM_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATM_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.124. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRAF_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRAF_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRAF_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRAF_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.323. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDKN2A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDKN2A_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDKN2A_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDKN2A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 6.957. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.111. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF2RA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF2RA_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF2RA_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF2RA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 6.655. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CTNNB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CTNNB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CTNNB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CTNNB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 6.230. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGFR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGFR_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGFR_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGFR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 4.098. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IGF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IGF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'IGF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column IGF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 6.655. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KRAS_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KRAS_altered'].var())\n",
            ">>> print(df.loc[~events, 'KRAS_altered'].var())\n",
            "\n",
            "A very low variance means that the column KRAS_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.111. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column LATS1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'LATS1_altered'].var())\n",
            ">>> print(df.loc[~events, 'LATS1_altered'].var())\n",
            "\n",
            "A very low variance means that the column LATS1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 6.230. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 7.126. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PTEN_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PTEN_altered'].var())\n",
            ">>> print(df.loc[~events, 'PTEN_altered'].var())\n",
            "\n",
            "A very low variance means that the column PTEN_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 3.600. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RAF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RAF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RAF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RAF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 6.957. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SLC2A1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SLC2A1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SLC2A1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SLC2A1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 6.957. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACLY_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACLY_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACLY_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACLY_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for CSF1R in ACC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HMGCR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HMGCR_altered'].var())\n",
            ">>> print(df.loc[~events, 'HMGCR_altered'].var())\n",
            "\n",
            "A very low variance means that the column HMGCR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IGF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IGF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'IGF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column IGF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column JAK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'JAK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'JAK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column JAK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KDR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KDR_altered'].var())\n",
            ">>> print(df.loc[~events, 'KDR_altered'].var())\n",
            "\n",
            "A very low variance means that the column KDR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column LDHA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'LDHA_altered'].var())\n",
            ">>> print(df.loc[~events, 'LDHA_altered'].var())\n",
            "\n",
            "A very low variance means that the column LDHA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP3K7_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP3K7_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP3K7_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP3K7_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for KDR in ACC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for LDHA in ACC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAPK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAPK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAPK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAPK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NDRG3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NDRG3_altered'].var())\n",
            ">>> print(df.loc[~events, 'NDRG3_altered'].var())\n",
            "\n",
            "A very low variance means that the column NDRG3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NF2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NF2_altered'].var())\n",
            ">>> print(df.loc[~events, 'NF2_altered'].var())\n",
            "\n",
            "A very low variance means that the column NF2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NFKB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NFKB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NFKB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NFKB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NOTCH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NOTCH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NOTCH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NOTCH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PDGFRA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PDGFRA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PDGFRA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PDGFRA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PIK3CA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PIK3CA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PIK3CA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PIK3CA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column PIK3CA_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RPS6KB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RPS6KB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RPS6KB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RPS6KB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STK11_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STK11_altered'].var())\n",
            ">>> print(df.loc[~events, 'STK11_altered'].var())\n",
            "\n",
            "A very low variance means that the column STK11_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TAZ_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TAZ_altered'].var())\n",
            ">>> print(df.loc[~events, 'TAZ_altered'].var())\n",
            "\n",
            "A very low variance means that the column TAZ_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TGFBR2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TGFBR2_altered'].var())\n",
            ">>> print(df.loc[~events, 'TGFBR2_altered'].var())\n",
            "\n",
            "A very low variance means that the column TGFBR2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.211. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TNFRSF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TNFRSF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'TNFRSF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column TNFRSF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column TNFRSF1A_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TSC1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TSC1_altered'].var())\n",
            ">>> print(df.loc[~events, 'TSC1_altered'].var())\n",
            "\n",
            "A very low variance means that the column TSC1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for TAZ in ACC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ULK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ULK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'ULK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column ULK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.151. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.104. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACLY_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACLY_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACLY_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACLY_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.106. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATM_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATM_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATM_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATM_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.208. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DVL3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DVL3_altered'].var())\n",
            ">>> print(df.loc[~events, 'DVL3_altered'].var())\n",
            "\n",
            "A very low variance means that the column DVL3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.106. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGLN2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGLN2_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGLN2_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGLN2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column EGLN2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.106. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ESRRA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ESRRA_altered'].var())\n",
            ">>> print(df.loc[~events, 'ESRRA_altered'].var())\n",
            "\n",
            "A very low variance means that the column ESRRA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.106. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column GSK3B_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'GSK3B_altered'].var())\n",
            ">>> print(df.loc[~events, 'GSK3B_altered'].var())\n",
            "\n",
            "A very low variance means that the column GSK3B_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.106. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HIF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HIF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'HIF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column HIF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.129. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'HK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column HK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column HK2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.106. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HMGCR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HMGCR_altered'].var())\n",
            ">>> print(df.loc[~events, 'HMGCR_altered'].var())\n",
            "\n",
            "A very low variance means that the column HMGCR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for HMGCR in ESCA due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n",
            "Model failed for IL1R1 in ESCA due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KDR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KDR_altered'].var())\n",
            ">>> print(df.loc[~events, 'KDR_altered'].var())\n",
            "\n",
            "A very low variance means that the column KDR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.129. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KRAS_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KRAS_altered'].var())\n",
            ">>> print(df.loc[~events, 'KRAS_altered'].var())\n",
            "\n",
            "A very low variance means that the column KRAS_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.106. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.166. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SLC16A1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SLC16A1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SLC16A1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SLC16A1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.106. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SLC2A1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SLC2A1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SLC2A1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SLC2A1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.106. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SOX9_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SOX9_altered'].var())\n",
            ">>> print(df.loc[~events, 'SOX9_altered'].var())\n",
            "\n",
            "A very low variance means that the column SOX9_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.129. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ULK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ULK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'ULK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column ULK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column ULK1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.106. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column LATS1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'LATS1_altered'].var())\n",
            ">>> print(df.loc[~events, 'LATS1_altered'].var())\n",
            "\n",
            "A very low variance means that the column LATS1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.100. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MDM2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MDM2_altered'].var())\n",
            ">>> print(df.loc[~events, 'MDM2_altered'].var())\n",
            "\n",
            "A very low variance means that the column MDM2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.100. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MTOR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MTOR_altered'].var())\n",
            ">>> print(df.loc[~events, 'MTOR_altered'].var())\n",
            "\n",
            "A very low variance means that the column MTOR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.112. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACA_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACA_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ALK_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ALK_altered'].var())\n",
            ">>> print(df.loc[~events, 'ALK_altered'].var())\n",
            "\n",
            "A very low variance means that the column ALK_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column ALK_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.117. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for ACACA in SARC due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1729: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = einsum(\"ab,i->ab\", risk_phi_x_x, denom) - einsum(\"ab,i->ab\", tie_phi_x_x, increasing_proportion * denom)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CCND1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CCND1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CCND1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CCND1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDKN1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDKN1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDKN1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDKN1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column CDKN1A_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.117. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for CCND1 in SARC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.143. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.117. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for CHEK1 in SARC due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF2RA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF2RA_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF2RA_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF2RA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.143. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM1_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM1_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DVL3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DVL3_altered'].var())\n",
            ">>> print(df.loc[~events, 'DVL3_altered'].var())\n",
            "\n",
            "A very low variance means that the column DVL3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.117. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGFR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGFR_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGFR_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGFR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.117. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for DAAM1 in SARC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'HK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column HK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.143. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KEAP1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KEAP1_altered'].var())\n",
            ">>> print(df.loc[~events, 'KEAP1_altered'].var())\n",
            "\n",
            "A very low variance means that the column KEAP1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column KEAP1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.117. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KRAS_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KRAS_altered'].var())\n",
            ">>> print(df.loc[~events, 'KRAS_altered'].var())\n",
            "\n",
            "A very low variance means that the column KRAS_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for KRAS in SARC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NOTCH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NOTCH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NOTCH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NOTCH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.143. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SETD2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SETD2_altered'].var())\n",
            ">>> print(df.loc[~events, 'SETD2_altered'].var())\n",
            "\n",
            "A very low variance means that the column SETD2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.117. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SMAD4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SMAD4_altered'].var())\n",
            ">>> print(df.loc[~events, 'SMAD4_altered'].var())\n",
            "\n",
            "A very low variance means that the column SMAD4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SOX17_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SOX17_altered'].var())\n",
            ">>> print(df.loc[~events, 'SOX17_altered'].var())\n",
            "\n",
            "A very low variance means that the column SOX17_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.117. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for SMAD4 in SARC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for SOX9 in SARC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1729: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = einsum(\"ab,i->ab\", risk_phi_x_x, denom) - einsum(\"ab,i->ab\", tie_phi_x_x, increasing_proportion * denom)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SOX9_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SOX9_altered'].var())\n",
            ">>> print(df.loc[~events, 'SOX9_altered'].var())\n",
            "\n",
            "A very low variance means that the column SOX9_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TNFRSF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TNFRSF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'TNFRSF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column TNFRSF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.117. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TSC2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TSC2_altered'].var())\n",
            ">>> print(df.loc[~events, 'TSC2_altered'].var())\n",
            "\n",
            "A very low variance means that the column TSC2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.164. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACLY_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACLY_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACLY_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACLY_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.208. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column AKT1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'AKT1_altered'].var())\n",
            ">>> print(df.loc[~events, 'AKT1_altered'].var())\n",
            "\n",
            "A very low variance means that the column AKT1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.167. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ARF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ARF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'ARF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column ARF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column AURKA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'AURKA_altered'].var())\n",
            ">>> print(df.loc[~events, 'AURKA_altered'].var())\n",
            "\n",
            "A very low variance means that the column AURKA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.142. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BBC3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BBC3_altered'].var())\n",
            ">>> print(df.loc[~events, 'BBC3_altered'].var())\n",
            "\n",
            "A very low variance means that the column BBC3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRCA1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRCA1_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRCA1_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRCA1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.225. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CCND1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CCND1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CCND1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CCND1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CCNE1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CCNE1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CCNE1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CCNE1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for CCND1 in CESC due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.142. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF2RA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF2RA_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF2RA_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF2RA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for CSF2RA in CESC due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM2_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM2_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.167. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DVL2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DVL2_altered'].var())\n",
            ">>> print(df.loc[~events, 'DVL2_altered'].var())\n",
            "\n",
            "A very low variance means that the column DVL2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column E2F1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'E2F1_altered'].var())\n",
            ">>> print(df.loc[~events, 'E2F1_altered'].var())\n",
            "\n",
            "A very low variance means that the column E2F1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FGFR1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FGFR1_altered'].var())\n",
            ">>> print(df.loc[~events, 'FGFR1_altered'].var())\n",
            "\n",
            "A very low variance means that the column FGFR1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FOXO3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FOXO3_altered'].var())\n",
            ">>> print(df.loc[~events, 'FOXO3_altered'].var())\n",
            "\n",
            "A very low variance means that the column FOXO3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column GLS2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'GLS2_altered'].var())\n",
            ">>> print(df.loc[~events, 'GLS2_altered'].var())\n",
            "\n",
            "A very low variance means that the column GLS2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HIF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HIF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'HIF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column HIF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.188. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KDR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KDR_altered'].var())\n",
            ">>> print(df.loc[~events, 'KDR_altered'].var())\n",
            "\n",
            "A very low variance means that the column KDR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.142. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KEAP1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KEAP1_altered'].var())\n",
            ">>> print(df.loc[~events, 'KEAP1_altered'].var())\n",
            "\n",
            "A very low variance means that the column KEAP1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KIT_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KIT_altered'].var())\n",
            ">>> print(df.loc[~events, 'KIT_altered'].var())\n",
            "\n",
            "A very low variance means that the column KIT_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.188. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.142. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAPK8_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAPK8_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAPK8_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAPK8_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.142. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MST1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MST1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MST1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MST1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NDRG3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NDRG3_altered'].var())\n",
            ">>> print(df.loc[~events, 'NDRG3_altered'].var())\n",
            "\n",
            "A very low variance means that the column NDRG3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARGC1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARGC1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARGC1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARGC1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PRKAA2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PRKAA2_altered'].var())\n",
            ">>> print(df.loc[~events, 'PRKAA2_altered'].var())\n",
            "\n",
            "A very low variance means that the column PRKAA2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RET_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RET_altered'].var())\n",
            ">>> print(df.loc[~events, 'RET_altered'].var())\n",
            "\n",
            "A very low variance means that the column RET_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SMAD3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SMAD3_altered'].var())\n",
            ">>> print(df.loc[~events, 'SMAD3_altered'].var())\n",
            "\n",
            "A very low variance means that the column SMAD3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.142. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SOX17_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SOX17_altered'].var())\n",
            ">>> print(df.loc[~events, 'SOX17_altered'].var())\n",
            "\n",
            "A very low variance means that the column SOX17_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SOX4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SOX4_altered'].var())\n",
            ">>> print(df.loc[~events, 'SOX4_altered'].var())\n",
            "\n",
            "A very low variance means that the column SOX4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STK3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STK3_altered'].var())\n",
            ">>> print(df.loc[~events, 'STK3_altered'].var())\n",
            "\n",
            "A very low variance means that the column STK3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TNFRSF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TNFRSF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'TNFRSF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column TNFRSF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ZHX2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ZHX2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ZHX2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ZHX2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACLY_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACLY_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACLY_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACLY_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.126. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ALK_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ALK_altered'].var())\n",
            ">>> print(df.loc[~events, 'ALK_altered'].var())\n",
            "\n",
            "A very low variance means that the column ALK_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.141. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CREBBP_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CREBBP_altered'].var())\n",
            ">>> print(df.loc[~events, 'CREBBP_altered'].var())\n",
            "\n",
            "A very low variance means that the column CREBBP_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM1_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM1_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGFR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGFR_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGFR_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGFR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.126. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ERBB2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ERBB2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ERBB2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ERBB2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column ERBB2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ESRRA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ESRRA_altered'].var())\n",
            ">>> print(df.loc[~events, 'ESRRA_altered'].var())\n",
            "\n",
            "A very low variance means that the column ESRRA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.319. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FGFR1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FGFR1_altered'].var())\n",
            ">>> print(df.loc[~events, 'FGFR1_altered'].var())\n",
            "\n",
            "A very low variance means that the column FGFR1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column FGFR1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IGF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IGF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'IGF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column IGF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.126. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column JAK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'JAK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'JAK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column JAK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column LATS2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'LATS2_altered'].var())\n",
            ">>> print(df.loc[~events, 'LATS2_altered'].var())\n",
            "\n",
            "A very low variance means that the column LATS2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column LATS2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K3_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K3_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for MAP2K3 in KIRC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for RB1 in KIRC due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SLC16A1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SLC16A1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SLC16A1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SLC16A1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SLC2A1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SLC2A1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SLC2A1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SLC2A1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for SLC2A1 in KIRC due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TNFRSF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TNFRSF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'TNFRSF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column TNFRSF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.126. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STK11_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STK11_altered'].var())\n",
            ">>> print(df.loc[~events, 'STK11_altered'].var())\n",
            "\n",
            "A very low variance means that the column STK11_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.123. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for TRAF4 in SKCM due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column YAP1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'YAP1_altered'].var())\n",
            ">>> print(df.loc[~events, 'YAP1_altered'].var())\n",
            "\n",
            "A very low variance means that the column YAP1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACA_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACA_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for YAP1 in SKCM due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACB_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACB_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column ACACB_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACLY_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACLY_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACLY_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACLY_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column APC_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'APC_altered'].var())\n",
            ">>> print(df.loc[~events, 'APC_altered'].var())\n",
            "\n",
            "A very low variance means that the column APC_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATR_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATR_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.191. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column AURKA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'AURKA_altered'].var())\n",
            ">>> print(df.loc[~events, 'AURKA_altered'].var())\n",
            "\n",
            "A very low variance means that the column AURKA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CCND2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CCND2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CCND2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CCND2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDK6_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDK6_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDK6_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDK6_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDKN2A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDKN2A_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDKN2A_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDKN2A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM1_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM1_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EIF4E_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EIF4E_altered'].var())\n",
            ">>> print(df.loc[~events, 'EIF4E_altered'].var())\n",
            "\n",
            "A very low variance means that the column EIF4E_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HMGCR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HMGCR_altered'].var())\n",
            ">>> print(df.loc[~events, 'HMGCR_altered'].var())\n",
            "\n",
            "A very low variance means that the column HMGCR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IGF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IGF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'IGF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column IGF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IKBKB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IKBKB_altered'].var())\n",
            ">>> print(df.loc[~events, 'IKBKB_altered'].var())\n",
            "\n",
            "A very low variance means that the column IKBKB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IL1R1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IL1R1_altered'].var())\n",
            ">>> print(df.loc[~events, 'IL1R1_altered'].var())\n",
            "\n",
            "A very low variance means that the column IL1R1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KDR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KDR_altered'].var())\n",
            ">>> print(df.loc[~events, 'KDR_altered'].var())\n",
            "\n",
            "A very low variance means that the column KDR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KIT_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KIT_altered'].var())\n",
            ">>> print(df.loc[~events, 'KIT_altered'].var())\n",
            "\n",
            "A very low variance means that the column KIT_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column LATS1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'LATS1_altered'].var())\n",
            ">>> print(df.loc[~events, 'LATS1_altered'].var())\n",
            "\n",
            "A very low variance means that the column LATS1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.231. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NFE2L2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NFE2L2_altered'].var())\n",
            ">>> print(df.loc[~events, 'NFE2L2_altered'].var())\n",
            "\n",
            "A very low variance means that the column NFE2L2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARGC1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARGC1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARGC1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARGC1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SETD2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SETD2_altered'].var())\n",
            ">>> print(df.loc[~events, 'SETD2_altered'].var())\n",
            "\n",
            "A very low variance means that the column SETD2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TLR1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TLR1_altered'].var())\n",
            ">>> print(df.loc[~events, 'TLR1_altered'].var())\n",
            "\n",
            "A very low variance means that the column TLR1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TSC1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TSC1_altered'].var())\n",
            ">>> print(df.loc[~events, 'TSC1_altered'].var())\n",
            "\n",
            "A very low variance means that the column TSC1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ULK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ULK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'ULK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column ULK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column ULK1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for TLR1 in UCS due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for CHEK1 in BRCA due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM1_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM1_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.104. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGLN2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGLN2_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGLN2_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGLN2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for EGLN2 in BRCA due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KIT_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KIT_altered'].var())\n",
            ">>> print(df.loc[~events, 'KIT_altered'].var())\n",
            "\n",
            "A very low variance means that the column KIT_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for NDRG3 in BRCA due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RET_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RET_altered'].var())\n",
            ">>> print(df.loc[~events, 'RET_altered'].var())\n",
            "\n",
            "A very low variance means that the column RET_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.125. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1729: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = einsum(\"ab,i->ab\", risk_phi_x_x, denom) - einsum(\"ab,i->ab\", tie_phi_x_x, increasing_proportion * denom)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RHEB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RHEB_altered'].var())\n",
            ">>> print(df.loc[~events, 'RHEB_altered'].var())\n",
            "\n",
            "A very low variance means that the column RHEB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for RHEB in BRCA due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for RPS6KB1 in BRCA due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1729: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = einsum(\"ab,i->ab\", risk_phi_x_x, denom) - einsum(\"ab,i->ab\", tie_phi_x_x, increasing_proportion * denom)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for SOX4 in BRCA due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACA_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACA_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACLY_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACLY_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACLY_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACLY_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACVR2A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACVR2A_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACVR2A_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACVR2A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATM_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATM_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATM_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATM_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATR_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATR_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CREBBP_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CREBBP_altered'].var())\n",
            ">>> print(df.loc[~events, 'CREBBP_altered'].var())\n",
            "\n",
            "A very low variance means that the column CREBBP_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.206. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGFR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGFR_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGFR_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGFR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EIF4E_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EIF4E_altered'].var())\n",
            ">>> print(df.loc[~events, 'EIF4E_altered'].var())\n",
            "\n",
            "A very low variance means that the column EIF4E_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ERBB2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ERBB2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ERBB2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ERBB2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.206. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column JAK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'JAK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'JAK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column JAK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KIT_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KIT_altered'].var())\n",
            ">>> print(df.loc[~events, 'KIT_altered'].var())\n",
            "\n",
            "A very low variance means that the column KIT_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.505. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP3K7_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP3K7_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP3K7_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP3K7_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column MAP3K7_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NDRG3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NDRG3_altered'].var())\n",
            ">>> print(df.loc[~events, 'NDRG3_altered'].var())\n",
            "\n",
            "A very low variance means that the column NDRG3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column NDRG3_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.250. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NOTCH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NOTCH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NOTCH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NOTCH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PIK3CA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PIK3CA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PIK3CA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PIK3CA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.250. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PRKAA2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PRKAA2_altered'].var())\n",
            ">>> print(df.loc[~events, 'PRKAA2_altered'].var())\n",
            "\n",
            "A very low variance means that the column PRKAA2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column PRKAA2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RAF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RAF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RAF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RAF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column RAF1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SLC2A1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SLC2A1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SLC2A1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SLC2A1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STAT3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STAT3_altered'].var())\n",
            ">>> print(df.loc[~events, 'STAT3_altered'].var())\n",
            "\n",
            "A very low variance means that the column STAT3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STK3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STK3_altered'].var())\n",
            ">>> print(df.loc[~events, 'STK3_altered'].var())\n",
            "\n",
            "A very low variance means that the column STK3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column STK3_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TP53_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TP53_altered'].var())\n",
            ">>> print(df.loc[~events, 'TP53_altered'].var())\n",
            "\n",
            "A very low variance means that the column TP53_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.206. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ULK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ULK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'ULK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column ULK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF2RA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF2RA_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF2RA_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF2RA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column CSF2RA_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.267. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DVL2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DVL2_altered'].var())\n",
            ">>> print(df.loc[~events, 'DVL2_altered'].var())\n",
            "\n",
            "A very low variance means that the column DVL2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 1.538. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FBXW7_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FBXW7_altered'].var())\n",
            ">>> print(df.loc[~events, 'FBXW7_altered'].var())\n",
            "\n",
            "A very low variance means that the column FBXW7_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column FBXW7_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.267. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FOXO3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FOXO3_altered'].var())\n",
            ">>> print(df.loc[~events, 'FOXO3_altered'].var())\n",
            "\n",
            "A very low variance means that the column FOXO3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column FOXO3_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.267. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IKBKB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IKBKB_altered'].var())\n",
            ">>> print(df.loc[~events, 'IKBKB_altered'].var())\n",
            "\n",
            "A very low variance means that the column IKBKB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.267. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K3_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K3_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column MAP2K3_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.267. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MTOR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MTOR_altered'].var())\n",
            ">>> print(df.loc[~events, 'MTOR_altered'].var())\n",
            "\n",
            "A very low variance means that the column MTOR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NFE2L2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NFE2L2_altered'].var())\n",
            ">>> print(df.loc[~events, 'NFE2L2_altered'].var())\n",
            "\n",
            "A very low variance means that the column NFE2L2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column NFE2L2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.267. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.267. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RET_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RET_altered'].var())\n",
            ">>> print(df.loc[~events, 'RET_altered'].var())\n",
            "\n",
            "A very low variance means that the column RET_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column RET_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.267. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SETD2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SETD2_altered'].var())\n",
            ">>> print(df.loc[~events, 'SETD2_altered'].var())\n",
            "\n",
            "A very low variance means that the column SETD2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.267. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for MTOR in UVM due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ULK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ULK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'ULK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column ULK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column ULK1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.267. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column YAP1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'YAP1_altered'].var())\n",
            ">>> print(df.loc[~events, 'YAP1_altered'].var())\n",
            "\n",
            "A very low variance means that the column YAP1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column YAP1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.267. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column AKT1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'AKT1_altered'].var())\n",
            ">>> print(df.loc[~events, 'AKT1_altered'].var())\n",
            "\n",
            "A very low variance means that the column AKT1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for AKT1 in OV due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FGFR1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FGFR1_altered'].var())\n",
            ">>> print(df.loc[~events, 'FGFR1_altered'].var())\n",
            "\n",
            "A very low variance means that the column FGFR1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for FGFR1 in OV due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAPK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAPK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAPK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAPK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for MAPK1 in OV due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RHOA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RHOA_altered'].var())\n",
            ">>> print(df.loc[~events, 'RHOA_altered'].var())\n",
            "\n",
            "A very low variance means that the column RHOA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for RHOA in OV due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACB_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACB_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CTNNB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CTNNB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CTNNB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CTNNB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.273. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for ACACB in MESO due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FGFR1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FGFR1_altered'].var())\n",
            ">>> print(df.loc[~events, 'FGFR1_altered'].var())\n",
            "\n",
            "A very low variance means that the column FGFR1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column FGFR1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.162. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KRAS_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KRAS_altered'].var())\n",
            ">>> print(df.loc[~events, 'KRAS_altered'].var())\n",
            "\n",
            "A very low variance means that the column KRAS_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.162. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAPK8_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAPK8_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAPK8_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAPK8_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column MAPK8_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.162. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MYC_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MYC_altered'].var())\n",
            ">>> print(df.loc[~events, 'MYC_altered'].var())\n",
            "\n",
            "A very low variance means that the column MYC_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column MYC_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.162. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PIK3CA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PIK3CA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PIK3CA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PIK3CA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column PIK3CA_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.162. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PTEN_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PTEN_altered'].var())\n",
            ">>> print(df.loc[~events, 'PTEN_altered'].var())\n",
            "\n",
            "A very low variance means that the column PTEN_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RHOA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RHOA_altered'].var())\n",
            ">>> print(df.loc[~events, 'RHOA_altered'].var())\n",
            "\n",
            "A very low variance means that the column RHOA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SREBF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SREBF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SREBF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SREBF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.273. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for PTEN in MESO due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for RHOA in MESO due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TSC1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TSC1_altered'].var())\n",
            ">>> print(df.loc[~events, 'TSC1_altered'].var())\n",
            "\n",
            "A very low variance means that the column TSC1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column TSC1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.162. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACLY_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACLY_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACLY_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACLY_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACVR2A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACVR2A_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACVR2A_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACVR2A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATR_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATR_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 9.000. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRAF_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRAF_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRAF_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRAF_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.200. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRCA2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRCA2_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRCA2_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRCA2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.277. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for ACLY in CHOL due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for ACVR2A in CHOL due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for CDK2 in CHOL due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.200. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGFR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGFR_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGFR_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGFR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.200. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'HK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column HK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KDR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KDR_altered'].var())\n",
            ">>> print(df.loc[~events, 'KDR_altered'].var())\n",
            "\n",
            "A very low variance means that the column KDR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 9.000. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for CHEK2 in CHOL due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for HK2 in CHOL due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column LATS2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'LATS2_altered'].var())\n",
            ">>> print(df.loc[~events, 'LATS2_altered'].var())\n",
            "\n",
            "A very low variance means that the column LATS2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.200. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column MAP2K1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.200. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NDRG3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NDRG3_altered'].var())\n",
            ">>> print(df.loc[~events, 'NDRG3_altered'].var())\n",
            "\n",
            "A very low variance means that the column NDRG3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 9.000. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NF2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NF2_altered'].var())\n",
            ">>> print(df.loc[~events, 'NF2_altered'].var())\n",
            "\n",
            "A very low variance means that the column NF2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.200. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PFKM_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PFKM_altered'].var())\n",
            ">>> print(df.loc[~events, 'PFKM_altered'].var())\n",
            "\n",
            "A very low variance means that the column PFKM_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PTEN_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PTEN_altered'].var())\n",
            ">>> print(df.loc[~events, 'PTEN_altered'].var())\n",
            "\n",
            "A very low variance means that the column PTEN_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RET_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RET_altered'].var())\n",
            ">>> print(df.loc[~events, 'RET_altered'].var())\n",
            "\n",
            "A very low variance means that the column RET_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SREBF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SREBF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SREBF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SREBF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.374. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for PFKM in CHOL due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for PTEN in CHOL due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for RET in CHOL due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for SREBF1 in CHOL due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for TGFBR2 in CHOL due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TRAF4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TRAF4_altered'].var())\n",
            ">>> print(df.loc[~events, 'TRAF4_altered'].var())\n",
            "\n",
            "A very low variance means that the column TRAF4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.200. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TSC1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TSC1_altered'].var())\n",
            ">>> print(df.loc[~events, 'TSC1_altered'].var())\n",
            "\n",
            "A very low variance means that the column TSC1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column TSC1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.200. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column YAP1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'YAP1_altered'].var())\n",
            ">>> print(df.loc[~events, 'YAP1_altered'].var())\n",
            "\n",
            "A very low variance means that the column YAP1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.200. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ZHX2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ZHX2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ZHX2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ZHX2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for ZHX2 in CHOL due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDK4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDK4_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDK4_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDK4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.103. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.145. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HIF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HIF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'HIF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column HIF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.145. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PDK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PDK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'PDK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column PDK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.103. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PFKM_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PFKM_altered'].var())\n",
            ">>> print(df.loc[~events, 'PFKM_altered'].var())\n",
            "\n",
            "A very low variance means that the column PFKM_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.126. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.103. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TNFRSF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TNFRSF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'TNFRSF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column TNFRSF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.103. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACA_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACA_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.171. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACB_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACB_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.140. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACVR2A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACVR2A_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACVR2A_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACVR2A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column ACVR2A_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column AKT1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'AKT1_altered'].var())\n",
            ">>> print(df.loc[~events, 'AKT1_altered'].var())\n",
            "\n",
            "A very low variance means that the column AKT1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ALK_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ALK_altered'].var())\n",
            ">>> print(df.loc[~events, 'ALK_altered'].var())\n",
            "\n",
            "A very low variance means that the column ALK_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATR_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATR_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.140. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRAF_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRAF_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRAF_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRAF_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.184. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRCA2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRCA2_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRCA2_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRCA2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.207. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for BRCA1 in PRAD due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDKN1B_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDKN1B_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDKN1B_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDKN1B_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.171. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CREBBP_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CREBBP_altered'].var())\n",
            ">>> print(df.loc[~events, 'CREBBP_altered'].var())\n",
            "\n",
            "A very low variance means that the column CREBBP_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.156. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.156. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for CHEK1 in PRAD due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CTNNB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CTNNB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CTNNB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CTNNB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.207. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM1_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM1_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM2_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM2_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.140. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGFR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGFR_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGFR_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGFR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column EGFR_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.140. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ERBB2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ERBB2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ERBB2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ERBB2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.140. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IGF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IGF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'IGF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column IGF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.140. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KDR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KDR_altered'].var())\n",
            ">>> print(df.loc[~events, 'KDR_altered'].var())\n",
            "\n",
            "A very low variance means that the column KDR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KEAP1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KEAP1_altered'].var())\n",
            ">>> print(df.loc[~events, 'KEAP1_altered'].var())\n",
            "\n",
            "A very low variance means that the column KEAP1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.140. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for JAK1 in PRAD due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MTOR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MTOR_altered'].var())\n",
            ">>> print(df.loc[~events, 'MTOR_altered'].var())\n",
            "\n",
            "A very low variance means that the column MTOR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.140. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for MET in PRAD due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PDGFRA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PDGFRA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PDGFRA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PDGFRA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PFKM_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PFKM_altered'].var())\n",
            ">>> print(df.loc[~events, 'PFKM_altered'].var())\n",
            "\n",
            "A very low variance means that the column PFKM_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PIK3CA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PIK3CA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PIK3CA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PIK3CA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.238. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARGC1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARGC1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARGC1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARGC1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PRKAA2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PRKAA2_altered'].var())\n",
            ">>> print(df.loc[~events, 'PRKAA2_altered'].var())\n",
            "\n",
            "A very low variance means that the column PRKAA2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PTEN_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PTEN_altered'].var())\n",
            ">>> print(df.loc[~events, 'PTEN_altered'].var())\n",
            "\n",
            "A very low variance means that the column PTEN_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.271. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RAF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RAF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RAF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RAF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.140. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for RAF1 in PRAD due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SETD2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SETD2_altered'].var())\n",
            ">>> print(df.loc[~events, 'SETD2_altered'].var())\n",
            "\n",
            "A very low variance means that the column SETD2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.184. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SMAD4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SMAD4_altered'].var())\n",
            ">>> print(df.loc[~events, 'SMAD4_altered'].var())\n",
            "\n",
            "A very low variance means that the column SMAD4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.156. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STAT3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STAT3_altered'].var())\n",
            ">>> print(df.loc[~events, 'STAT3_altered'].var())\n",
            "\n",
            "A very low variance means that the column STAT3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.156. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STK3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STK3_altered'].var())\n",
            ">>> print(df.loc[~events, 'STK3_altered'].var())\n",
            "\n",
            "A very low variance means that the column STK3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TLR1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TLR1_altered'].var())\n",
            ">>> print(df.loc[~events, 'TLR1_altered'].var())\n",
            "\n",
            "A very low variance means that the column TLR1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TNFRSF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TNFRSF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'TNFRSF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column TNFRSF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for STK3 in PRAD due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TSC2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TSC2_altered'].var())\n",
            ">>> print(df.loc[~events, 'TSC2_altered'].var())\n",
            "\n",
            "A very low variance means that the column TSC2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.156. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ZHX2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ZHX2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ZHX2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ZHX2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.140. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACA_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACA_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 4.000. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ALK_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ALK_altered'].var())\n",
            ">>> print(df.loc[~events, 'ALK_altered'].var())\n",
            "\n",
            "A very low variance means that the column ALK_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 4.000. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column APC_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'APC_altered'].var())\n",
            ">>> print(df.loc[~events, 'APC_altered'].var())\n",
            "\n",
            "A very low variance means that the column APC_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column APC_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for VHL in PRAD due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATR_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATR_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRAF_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRAF_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRAF_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRAF_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRCA2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRCA2_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRCA2_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRCA2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDKN2A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDKN2A_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDKN2A_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDKN2A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDKN2C_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDKN2C_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDKN2C_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDKN2C_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF2RA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF2RA_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF2RA_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF2RA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column CSF2RA_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DVL2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DVL2_altered'].var())\n",
            ">>> print(df.loc[~events, 'DVL2_altered'].var())\n",
            "\n",
            "A very low variance means that the column DVL2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGFR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGFR_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGFR_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGFR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for EGFR in PCPG due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FGFR1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FGFR1_altered'].var())\n",
            ">>> print(df.loc[~events, 'FGFR1_altered'].var())\n",
            "\n",
            "A very low variance means that the column FGFR1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.192. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column JUN_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'JUN_altered'].var())\n",
            ">>> print(df.loc[~events, 'JUN_altered'].var())\n",
            "\n",
            "A very low variance means that the column JUN_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column LATS2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'LATS2_altered'].var())\n",
            ">>> print(df.loc[~events, 'LATS2_altered'].var())\n",
            "\n",
            "A very low variance means that the column LATS2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 4.000. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MTOR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MTOR_altered'].var())\n",
            ">>> print(df.loc[~events, 'MTOR_altered'].var())\n",
            "\n",
            "A very low variance means that the column MTOR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.471. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NFE2L2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NFE2L2_altered'].var())\n",
            ">>> print(df.loc[~events, 'NFE2L2_altered'].var())\n",
            "\n",
            "A very low variance means that the column NFE2L2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column NFE2L2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NFKB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NFKB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NFKB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NFKB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column NFKB1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PFKM_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PFKM_altered'].var())\n",
            ">>> print(df.loc[~events, 'PFKM_altered'].var())\n",
            "\n",
            "A very low variance means that the column PFKM_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column PFKM_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PIK3CA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PIK3CA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PIK3CA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PIK3CA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARGC1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARGC1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARGC1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARGC1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column PPARGC1A_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RET_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RET_altered'].var())\n",
            ">>> print(df.loc[~events, 'RET_altered'].var())\n",
            "\n",
            "A very low variance means that the column RET_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.320. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RPS6KB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RPS6KB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RPS6KB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RPS6KB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SETD2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SETD2_altered'].var())\n",
            ">>> print(df.loc[~events, 'SETD2_altered'].var())\n",
            "\n",
            "A very low variance means that the column SETD2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STAT3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STAT3_altered'].var())\n",
            ">>> print(df.loc[~events, 'STAT3_altered'].var())\n",
            "\n",
            "A very low variance means that the column STAT3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TP53_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TP53_altered'].var())\n",
            ">>> print(df.loc[~events, 'TP53_altered'].var())\n",
            "\n",
            "A very low variance means that the column TP53_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 4.000. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ULK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ULK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'ULK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column ULK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column VHL_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'VHL_altered'].var())\n",
            ">>> print(df.loc[~events, 'VHL_altered'].var())\n",
            "\n",
            "A very low variance means that the column VHL_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.233. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ZHX2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ZHX2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ZHX2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ZHX2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column ZHX2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.137. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for SETD2 in PCPG due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.108. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STAT5A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STAT5A_altered'].var())\n",
            ">>> print(df.loc[~events, 'STAT5A_altered'].var())\n",
            "\n",
            "A very low variance means that the column STAT5A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.108. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CCNE1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CCNE1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CCNE1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CCNE1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.114. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DVL2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DVL2_altered'].var())\n",
            ">>> print(df.loc[~events, 'DVL2_altered'].var())\n",
            "\n",
            "A very low variance means that the column DVL2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.114. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column JUN_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'JUN_altered'].var())\n",
            ">>> print(df.loc[~events, 'JUN_altered'].var())\n",
            "\n",
            "A very low variance means that the column JUN_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.104. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NDRG3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NDRG3_altered'].var())\n",
            ">>> print(df.loc[~events, 'NDRG3_altered'].var())\n",
            "\n",
            "A very low variance means that the column NDRG3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.104. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STAT5A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STAT5A_altered'].var())\n",
            ">>> print(df.loc[~events, 'STAT5A_altered'].var())\n",
            "\n",
            "A very low variance means that the column STAT5A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.104. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SOX4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SOX4_altered'].var())\n",
            ">>> print(df.loc[~events, 'SOX4_altered'].var())\n",
            "\n",
            "A very low variance means that the column SOX4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.103. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column AKT1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'AKT1_altered'].var())\n",
            ">>> print(df.loc[~events, 'AKT1_altered'].var())\n",
            "\n",
            "A very low variance means that the column AKT1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATR_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATR_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRAF_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRAF_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRAF_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRAF_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDKN2A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDKN2A_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDKN2A_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDKN2A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for ATR in THYM due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CTNNB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CTNNB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CTNNB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CTNNB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM1_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM1_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IGF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IGF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'IGF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column IGF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KIT_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KIT_altered'].var())\n",
            ">>> print(df.loc[~events, 'KIT_altered'].var())\n",
            "\n",
            "A very low variance means that the column KIT_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column KIT_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KRAS_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KRAS_altered'].var())\n",
            ">>> print(df.loc[~events, 'KRAS_altered'].var())\n",
            "\n",
            "A very low variance means that the column KRAS_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.282. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NF2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NF2_altered'].var())\n",
            ">>> print(df.loc[~events, 'NF2_altered'].var())\n",
            "\n",
            "A very low variance means that the column NF2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column NF2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PFKM_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PFKM_altered'].var())\n",
            ">>> print(df.loc[~events, 'PFKM_altered'].var())\n",
            "\n",
            "A very low variance means that the column PFKM_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PIK3CA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PIK3CA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PIK3CA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PIK3CA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.282. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARGC1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARGC1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARGC1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARGC1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RHOA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RHOA_altered'].var())\n",
            ">>> print(df.loc[~events, 'RHOA_altered'].var())\n",
            "\n",
            "A very low variance means that the column RHOA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SETD2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SETD2_altered'].var())\n",
            ">>> print(df.loc[~events, 'SETD2_altered'].var())\n",
            "\n",
            "A very low variance means that the column SETD2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SLC16A1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SLC16A1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SLC16A1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SLC16A1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SLC2A1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SLC2A1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SLC2A1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SLC2A1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for PFKM in THYM due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for SETD2 in THYM due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for SLC16A1 in THYM due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for SLC2A1 in THYM due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for SREBF1 in THYM due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SOX4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SOX4_altered'].var())\n",
            ">>> print(df.loc[~events, 'SOX4_altered'].var())\n",
            "\n",
            "A very low variance means that the column SOX4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SREBF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SREBF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SREBF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SREBF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TGFBR2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TGFBR2_altered'].var())\n",
            ">>> print(df.loc[~events, 'TGFBR2_altered'].var())\n",
            "\n",
            "A very low variance means that the column TGFBR2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column VHL_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'VHL_altered'].var())\n",
            ">>> print(df.loc[~events, 'VHL_altered'].var())\n",
            "\n",
            "A very low variance means that the column VHL_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACLY_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACLY_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACLY_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACLY_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CCNE1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CCNE1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CCNE1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CCNE1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1729: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = einsum(\"ab,i->ab\", risk_phi_x_x, denom) - einsum(\"ab,i->ab\", tie_phi_x_x, increasing_proportion * denom)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDK4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDK4_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDK4_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDK4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for CCNE1 in LIHC due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n",
            "Model failed for CDK4 in LIHC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM2_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM2_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FGFR1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FGFR1_altered'].var())\n",
            ">>> print(df.loc[~events, 'FGFR1_altered'].var())\n",
            "\n",
            "A very low variance means that the column FGFR1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.113. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HIF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HIF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'HIF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column HIF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for GSK3B in LIHC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for HIF1A in LIHC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for MAP2K1 in LIHC due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in multiply\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: invalid value encountered in subtract\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in multiply\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1728: RuntimeWarning: invalid value encountered in subtract\n",
            "  numer = risk_phi_x - multiply.outer(increasing_proportion, tie_phi_x)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MYC_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MYC_altered'].var())\n",
            ">>> print(df.loc[~events, 'MYC_altered'].var())\n",
            "\n",
            "A very low variance means that the column MYC_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for MYC in LIHC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NOTCH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NOTCH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NOTCH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NOTCH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.149. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1727: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / (risk_phi - increasing_proportion * tie_phi)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1729: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = einsum(\"ab,i->ab\", risk_phi_x_x, denom) - einsum(\"ab,i->ab\", tie_phi_x_x, increasing_proportion * denom)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RET_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RET_altered'].var())\n",
            ">>> print(df.loc[~events, 'RET_altered'].var())\n",
            "\n",
            "A very low variance means that the column RET_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.127. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for PRKAA2 in LIHC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STK11_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STK11_altered'].var())\n",
            ">>> print(df.loc[~events, 'STK11_altered'].var())\n",
            "\n",
            "A very low variance means that the column STK11_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TGFBR2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TGFBR2_altered'].var())\n",
            ">>> print(df.loc[~events, 'TGFBR2_altered'].var())\n",
            "\n",
            "A very low variance means that the column TGFBR2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for STK11 in LIHC due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n",
            "Model failed for TGFBR2 in LIHC due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDK6_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDK6_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDK6_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDK6_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.126. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HIF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HIF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'HIF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column HIF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MET_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MET_altered'].var())\n",
            ">>> print(df.loc[~events, 'MET_altered'].var())\n",
            "\n",
            "A very low variance means that the column MET_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.154. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NDRG3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NDRG3_altered'].var())\n",
            ">>> print(df.loc[~events, 'NDRG3_altered'].var())\n",
            "\n",
            "A very low variance means that the column NDRG3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.115. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STAT3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STAT3_altered'].var())\n",
            ">>> print(df.loc[~events, 'STAT3_altered'].var())\n",
            "\n",
            "A very low variance means that the column STAT3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.136. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDK4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDK4_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDK4_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDK4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.186. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDKN1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDKN1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDKN1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDKN1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.122. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column GSK3B_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'GSK3B_altered'].var())\n",
            ">>> print(df.loc[~events, 'GSK3B_altered'].var())\n",
            "\n",
            "A very low variance means that the column GSK3B_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.191. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HMGCR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HMGCR_altered'].var())\n",
            ">>> print(df.loc[~events, 'HMGCR_altered'].var())\n",
            "\n",
            "A very low variance means that the column HMGCR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.238. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAPK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAPK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAPK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAPK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.149. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAPK8_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAPK8_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAPK8_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAPK8_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.204. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MDM2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MDM2_altered'].var())\n",
            ">>> print(df.loc[~events, 'MDM2_altered'].var())\n",
            "\n",
            "A very low variance means that the column MDM2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.191. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MDM4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MDM4_altered'].var())\n",
            ">>> print(df.loc[~events, 'MDM4_altered'].var())\n",
            "\n",
            "A very low variance means that the column MDM4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.166. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RHEB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RHEB_altered'].var())\n",
            ">>> print(df.loc[~events, 'RHEB_altered'].var())\n",
            "\n",
            "A very low variance means that the column RHEB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.143. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TNFRSF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TNFRSF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'TNFRSF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column TNFRSF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.212. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TRAF4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TRAF4_altered'].var())\n",
            ">>> print(df.loc[~events, 'TRAF4_altered'].var())\n",
            "\n",
            "A very low variance means that the column TRAF4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.181. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column VHL_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'VHL_altered'].var())\n",
            ">>> print(df.loc[~events, 'VHL_altered'].var())\n",
            "\n",
            "A very low variance means that the column VHL_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.114. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACA_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACA_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.236. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACB_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACB_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.189. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACLY_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACLY_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACLY_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACLY_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACVR2A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACVR2A_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACVR2A_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACVR2A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.236. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ALK_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ALK_altered'].var())\n",
            ">>> print(df.loc[~events, 'ALK_altered'].var())\n",
            "\n",
            "A very low variance means that the column ALK_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.170. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATR_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATR_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.170. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRAF_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRAF_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRAF_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRAF_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.206. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRCA1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRCA1_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRCA1_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRCA1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRCA2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRCA2_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRCA2_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRCA2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.285. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.170. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDKN1B_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDKN1B_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDKN1B_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDKN1B_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CREBBP_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CREBBP_altered'].var())\n",
            ">>> print(df.loc[~events, 'CREBBP_altered'].var())\n",
            "\n",
            "A very low variance means that the column CREBBP_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.250. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF2RA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF2RA_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF2RA_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF2RA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.206. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CTNNB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CTNNB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CTNNB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CTNNB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.206. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM1_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM1_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM2_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM2_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.250. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DVL2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DVL2_altered'].var())\n",
            ">>> print(df.loc[~events, 'DVL2_altered'].var())\n",
            "\n",
            "A very low variance means that the column DVL2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.170. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGFR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGFR_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGFR_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGFR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ERBB2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ERBB2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ERBB2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ERBB2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.236. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ESRRA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ESRRA_altered'].var())\n",
            ">>> print(df.loc[~events, 'ESRRA_altered'].var())\n",
            "\n",
            "A very low variance means that the column ESRRA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FGFR1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FGFR1_altered'].var())\n",
            ">>> print(df.loc[~events, 'FGFR1_altered'].var())\n",
            "\n",
            "A very low variance means that the column FGFR1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.170. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FOXO3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FOXO3_altered'].var())\n",
            ">>> print(df.loc[~events, 'FOXO3_altered'].var())\n",
            "\n",
            "A very low variance means that the column FOXO3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column GSK3B_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'GSK3B_altered'].var())\n",
            ">>> print(df.loc[~events, 'GSK3B_altered'].var())\n",
            "\n",
            "A very low variance means that the column GSK3B_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HIF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HIF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'HIF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column HIF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.189. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'HK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column HK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HMGCR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HMGCR_altered'].var())\n",
            ">>> print(df.loc[~events, 'HMGCR_altered'].var())\n",
            "\n",
            "A very low variance means that the column HMGCR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IGF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IGF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'IGF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column IGF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IKBKB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IKBKB_altered'].var())\n",
            ">>> print(df.loc[~events, 'IKBKB_altered'].var())\n",
            "\n",
            "A very low variance means that the column IKBKB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IL1R1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IL1R1_altered'].var())\n",
            ">>> print(df.loc[~events, 'IL1R1_altered'].var())\n",
            "\n",
            "A very low variance means that the column IL1R1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column JAK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'JAK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'JAK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column JAK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.206. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KEAP1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KEAP1_altered'].var())\n",
            ">>> print(df.loc[~events, 'KEAP1_altered'].var())\n",
            "\n",
            "A very low variance means that the column KEAP1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KIT_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KIT_altered'].var())\n",
            ">>> print(df.loc[~events, 'KIT_altered'].var())\n",
            "\n",
            "A very low variance means that the column KIT_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.189. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column LATS1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'LATS1_altered'].var())\n",
            ">>> print(df.loc[~events, 'LATS1_altered'].var())\n",
            "\n",
            "A very low variance means that the column LATS1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.206. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column LATS2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'LATS2_altered'].var())\n",
            ">>> print(df.loc[~events, 'LATS2_altered'].var())\n",
            "\n",
            "A very low variance means that the column LATS2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP3K7_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP3K7_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP3K7_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP3K7_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAPK8_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAPK8_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAPK8_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAPK8_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.170. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MDM2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MDM2_altered'].var())\n",
            ">>> print(df.loc[~events, 'MDM2_altered'].var())\n",
            "\n",
            "A very low variance means that the column MDM2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MDM4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MDM4_altered'].var())\n",
            ">>> print(df.loc[~events, 'MDM4_altered'].var())\n",
            "\n",
            "A very low variance means that the column MDM4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MET_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MET_altered'].var())\n",
            ">>> print(df.loc[~events, 'MET_altered'].var())\n",
            "\n",
            "A very low variance means that the column MET_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MST1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MST1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MST1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MST1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column MST1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MTOR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MTOR_altered'].var())\n",
            ">>> print(df.loc[~events, 'MTOR_altered'].var())\n",
            "\n",
            "A very low variance means that the column MTOR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NF2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NF2_altered'].var())\n",
            ">>> print(df.loc[~events, 'NF2_altered'].var())\n",
            "\n",
            "A very low variance means that the column NF2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NFE2L2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NFE2L2_altered'].var())\n",
            ">>> print(df.loc[~events, 'NFE2L2_altered'].var())\n",
            "\n",
            "A very low variance means that the column NFE2L2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NOTCH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NOTCH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NOTCH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NOTCH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.170. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PDGFRA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PDGFRA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PDGFRA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PDGFRA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.206. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PDK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PDK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'PDK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column PDK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARA_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARA_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PRKAA2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PRKAA2_altered'].var())\n",
            ">>> print(df.loc[~events, 'PRKAA2_altered'].var())\n",
            "\n",
            "A very low variance means that the column PRKAA2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RAF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RAF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RAF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RAF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.147. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RET_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RET_altered'].var())\n",
            ">>> print(df.loc[~events, 'RET_altered'].var())\n",
            "\n",
            "A very low variance means that the column RET_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.189. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RHOA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RHOA_altered'].var())\n",
            ">>> print(df.loc[~events, 'RHOA_altered'].var())\n",
            "\n",
            "A very low variance means that the column RHOA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SETD2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SETD2_altered'].var())\n",
            ">>> print(df.loc[~events, 'SETD2_altered'].var())\n",
            "\n",
            "A very low variance means that the column SETD2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.222. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SLC16A1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SLC16A1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SLC16A1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SLC16A1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.170. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SMAD3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SMAD3_altered'].var())\n",
            ">>> print(df.loc[~events, 'SMAD3_altered'].var())\n",
            "\n",
            "A very low variance means that the column SMAD3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.189. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SOX17_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SOX17_altered'].var())\n",
            ">>> print(df.loc[~events, 'SOX17_altered'].var())\n",
            "\n",
            "A very low variance means that the column SOX17_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SOX4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SOX4_altered'].var())\n",
            ">>> print(df.loc[~events, 'SOX4_altered'].var())\n",
            "\n",
            "A very low variance means that the column SOX4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for SOX17 in READ due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STAT5A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STAT5A_altered'].var())\n",
            ">>> print(df.loc[~events, 'STAT5A_altered'].var())\n",
            "\n",
            "A very low variance means that the column STAT5A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STK11_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STK11_altered'].var())\n",
            ">>> print(df.loc[~events, 'STK11_altered'].var())\n",
            "\n",
            "A very low variance means that the column STK11_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TLR1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TLR1_altered'].var())\n",
            ">>> print(df.loc[~events, 'TLR1_altered'].var())\n",
            "\n",
            "A very low variance means that the column TLR1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TNFRSF1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TNFRSF1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'TNFRSF1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column TNFRSF1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TSC1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TSC1_altered'].var())\n",
            ">>> print(df.loc[~events, 'TSC1_altered'].var())\n",
            "\n",
            "A very low variance means that the column TSC1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TSC2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TSC2_altered'].var())\n",
            ">>> print(df.loc[~events, 'TSC2_altered'].var())\n",
            "\n",
            "A very low variance means that the column TSC2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.170. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ULK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ULK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'ULK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column ULK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.170. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column VHL_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'VHL_altered'].var())\n",
            ">>> print(df.loc[~events, 'VHL_altered'].var())\n",
            "\n",
            "A very low variance means that the column VHL_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ZHX2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ZHX2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ZHX2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ZHX2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.121. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACLY_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACLY_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACLY_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACLY_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDKN1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDKN1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDKN1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDKN1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.242. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CSF1R_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CSF1R_altered'].var())\n",
            ">>> print(df.loc[~events, 'CSF1R_altered'].var())\n",
            "\n",
            "A very low variance means that the column CSF1R_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column CSF1R_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for ACLY in KICH due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column LATS2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'LATS2_altered'].var())\n",
            ">>> print(df.loc[~events, 'LATS2_altered'].var())\n",
            "\n",
            "A very low variance means that the column LATS2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.533. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MTOR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MTOR_altered'].var())\n",
            ">>> print(df.loc[~events, 'MTOR_altered'].var())\n",
            "\n",
            "A very low variance means that the column MTOR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.242. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NOTCH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NOTCH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NOTCH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NOTCH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column NOTCH1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SETD2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SETD2_altered'].var())\n",
            ">>> print(df.loc[~events, 'SETD2_altered'].var())\n",
            "\n",
            "A very low variance means that the column SETD2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column SETD2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TSC1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TSC1_altered'].var())\n",
            ">>> print(df.loc[~events, 'TSC1_altered'].var())\n",
            "\n",
            "A very low variance means that the column TSC1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.242. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column YAP1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'YAP1_altered'].var())\n",
            ">>> print(df.loc[~events, 'YAP1_altered'].var())\n",
            "\n",
            "A very low variance means that the column YAP1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACA_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACA_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for YAP1 in KICH due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACB_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACB_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.242. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column APC_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'APC_altered'].var())\n",
            ">>> print(df.loc[~events, 'APC_altered'].var())\n",
            "\n",
            "A very low variance means that the column APC_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATM_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATM_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATM_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATM_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column ATM_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATR_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATR_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.242. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column AURKA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'AURKA_altered'].var())\n",
            ">>> print(df.loc[~events, 'AURKA_altered'].var())\n",
            "\n",
            "A very low variance means that the column AURKA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRAF_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRAF_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRAF_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRAF_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRCA1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRCA1_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRCA1_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRCA1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.242. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRCA2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRCA2_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRCA2_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRCA2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CCND2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CCND2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CCND2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CCND2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column CHEK2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for CCND2 in DLBC due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM2_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM2_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column E2F1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'E2F1_altered'].var())\n",
            ">>> print(df.loc[~events, 'E2F1_altered'].var())\n",
            "\n",
            "A very low variance means that the column E2F1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGFR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGFR_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGFR_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGFR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'HK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column HK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column HK2_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column HMGCR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'HMGCR_altered'].var())\n",
            ">>> print(df.loc[~events, 'HMGCR_altered'].var())\n",
            "\n",
            "A very low variance means that the column HMGCR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column IKBKB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'IKBKB_altered'].var())\n",
            ">>> print(df.loc[~events, 'IKBKB_altered'].var())\n",
            "\n",
            "A very low variance means that the column IKBKB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column JAK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'JAK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'JAK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column JAK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column JAK1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KDR_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KDR_altered'].var())\n",
            ">>> print(df.loc[~events, 'KDR_altered'].var())\n",
            "\n",
            "A very low variance means that the column KDR_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.331. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.242. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K3_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K3_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.242. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MET_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MET_altered'].var())\n",
            ">>> print(df.loc[~events, 'MET_altered'].var())\n",
            "\n",
            "A very low variance means that the column MET_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column MET_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for KRAS in DLBC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.292. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PDHA1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PDHA1_altered'].var())\n",
            ">>> print(df.loc[~events, 'PDHA1_altered'].var())\n",
            "\n",
            "A very low variance means that the column PDHA1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PTEN_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PTEN_altered'].var())\n",
            ">>> print(df.loc[~events, 'PTEN_altered'].var())\n",
            "\n",
            "A very low variance means that the column PTEN_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 2.000. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RAF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RAF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RAF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RAF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.292. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SLC16A1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SLC16A1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SLC16A1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SLC16A1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SOX17_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SOX17_altered'].var())\n",
            ">>> print(df.loc[~events, 'SOX17_altered'].var())\n",
            "\n",
            "A very low variance means that the column SOX17_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STK11_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STK11_altered'].var())\n",
            ">>> print(df.loc[~events, 'STK11_altered'].var())\n",
            "\n",
            "A very low variance means that the column STK11_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STK3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STK3_altered'].var())\n",
            ">>> print(df.loc[~events, 'STK3_altered'].var())\n",
            "\n",
            "A very low variance means that the column STK3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column STK3_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.174. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column TP53_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'TP53_altered'].var())\n",
            ">>> print(df.loc[~events, 'TP53_altered'].var())\n",
            "\n",
            "A very low variance means that the column TP53_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.392. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ZHX2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ZHX2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ZHX2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ZHX2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 2.000. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for SOX17 in DLBC due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACA_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACA_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACA_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACA_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.188. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACACB_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACACB_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACACB_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACACB_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.155. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACLY_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACLY_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACLY_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACLY_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.172. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ACVR2A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ACVR2A_altered'].var())\n",
            ">>> print(df.loc[~events, 'ACVR2A_altered'].var())\n",
            "\n",
            "A very low variance means that the column ACVR2A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.172. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ALK_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ALK_altered'].var())\n",
            ">>> print(df.loc[~events, 'ALK_altered'].var())\n",
            "\n",
            "A very low variance means that the column ALK_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.134. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ATM_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ATM_altered'].var())\n",
            ">>> print(df.loc[~events, 'ATM_altered'].var())\n",
            "\n",
            "A very low variance means that the column ATM_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.155. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRAF_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRAF_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRAF_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRAF_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.172. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column BRCA1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'BRCA1_altered'].var())\n",
            ">>> print(df.loc[~events, 'BRCA1_altered'].var())\n",
            "\n",
            "A very low variance means that the column BRCA1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.155. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CDH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CDH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CDH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CDH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CHEK2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CHEK2_altered'].var())\n",
            ">>> print(df.loc[~events, 'CHEK2_altered'].var())\n",
            "\n",
            "A very low variance means that the column CHEK2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column CTNNB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'CTNNB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'CTNNB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column CTNNB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.134. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1731: RuntimeWarning: divide by zero encountered in divide\n",
            "  denom = 1.0 / np.array([risk_phi])\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: invalid value encountered in scalar add\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DAAM2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DAAM2_altered'].var())\n",
            ">>> print(df.loc[~events, 'DAAM2_altered'].var())\n",
            "\n",
            "A very low variance means that the column DAAM2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for CSF1R in KIRP due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n",
            "Model failed for DAAM2 in KIRP due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column DVL3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'DVL3_altered'].var())\n",
            ">>> print(df.loc[~events, 'DVL3_altered'].var())\n",
            "\n",
            "A very low variance means that the column DVL3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column EGLN2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'EGLN2_altered'].var())\n",
            ">>> print(df.loc[~events, 'EGLN2_altered'].var())\n",
            "\n",
            "A very low variance means that the column EGLN2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ERBB2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ERBB2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ERBB2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ERBB2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.155. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column FBXW7_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'FBXW7_altered'].var())\n",
            ">>> print(df.loc[~events, 'FBXW7_altered'].var())\n",
            "\n",
            "A very low variance means that the column FBXW7_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for HIF1A in KIRP due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KEAP1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KEAP1_altered'].var())\n",
            ">>> print(df.loc[~events, 'KEAP1_altered'].var())\n",
            "\n",
            "A very low variance means that the column KEAP1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.134. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1679: RuntimeWarning: overflow encountered in exp\n",
            "  scores = weights * exp(dot(X, beta))\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1733: RuntimeWarning: invalid value encountered in multiply\n",
            "  a1 = risk_phi_x_x * denom\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1735: RuntimeWarning: invalid value encountered in multiply\n",
            "  summand = numer * denom[:, None]\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1740: RuntimeWarning: divide by zero encountered in log\n",
            "  log_lik = log_lik + dot(x_death_sum, beta) + weighted_average * log(denom).sum()\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1530: LinAlgWarning: Ill-conditioned matrix (rcond=0): result may not be accurate.\n",
            "  inv_h_dot_g_T = spsolve(-h, g, assume_a=\"pos\", check_finite=False)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KIT_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KIT_altered'].var())\n",
            ">>> print(df.loc[~events, 'KIT_altered'].var())\n",
            "\n",
            "A very low variance means that the column KIT_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column KRAS_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'KRAS_altered'].var())\n",
            ">>> print(df.loc[~events, 'KRAS_altered'].var())\n",
            "\n",
            "A very low variance means that the column KRAS_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.172. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column LATS1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'LATS1_altered'].var())\n",
            ">>> print(df.loc[~events, 'LATS1_altered'].var())\n",
            "\n",
            "A very low variance means that the column LATS1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column LATS1_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.155. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for KIT in KIRP due to: delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP3K7_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP3K7_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP3K7_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP3K7_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column MAP3K7_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MST1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MST1_altered'].var())\n",
            ">>> print(df.loc[~events, 'MST1_altered'].var())\n",
            "\n",
            "A very low variance means that the column MST1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.155. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NFE2L2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NFE2L2_altered'].var())\n",
            ">>> print(df.loc[~events, 'NFE2L2_altered'].var())\n",
            "\n",
            "A very low variance means that the column NFE2L2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.188. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column NOTCH1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'NOTCH1_altered'].var())\n",
            ">>> print(df.loc[~events, 'NOTCH1_altered'].var())\n",
            "\n",
            "A very low variance means that the column NOTCH1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.134. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PFKM_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PFKM_altered'].var())\n",
            ">>> print(df.loc[~events, 'PFKM_altered'].var())\n",
            "\n",
            "A very low variance means that the column PFKM_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column PFKM_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PPARGC1A_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PPARGC1A_altered'].var())\n",
            ">>> print(df.loc[~events, 'PPARGC1A_altered'].var())\n",
            "\n",
            "A very low variance means that the column PPARGC1A_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1163: ConvergenceWarning: Column PPARGC1A_altered has high sample correlation with the duration column. This may harm convergence. This could be a form of 'complete separation'.     See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.134. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PTEN_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PTEN_altered'].var())\n",
            ">>> print(df.loc[~events, 'PTEN_altered'].var())\n",
            "\n",
            "A very low variance means that the column PTEN_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.203. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RAF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RAF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RAF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RAF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.134. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SMAD4_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SMAD4_altered'].var())\n",
            ">>> print(df.loc[~events, 'SMAD4_altered'].var())\n",
            "\n",
            "A very low variance means that the column SMAD4_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SOX17_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SOX17_altered'].var())\n",
            ">>> print(df.loc[~events, 'SOX17_altered'].var())\n",
            "\n",
            "A very low variance means that the column SOX17_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column SREBF1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'SREBF1_altered'].var())\n",
            ">>> print(df.loc[~events, 'SREBF1_altered'].var())\n",
            "\n",
            "A very low variance means that the column SREBF1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model failed for SMAD4 in KIRP due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n",
            "Model failed for SOX17 in KIRP due to: Convergence halted due to matrix inversion problems. Suspicion is high collinearity. Please see the following tips in the lifelines documentation: https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-modelMatrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column STK11_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'STK11_altered'].var())\n",
            ">>> print(df.loc[~events, 'STK11_altered'].var())\n",
            "\n",
            "A very low variance means that the column STK11_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ULK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ULK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'ULK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column ULK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.134. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column VHL_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'VHL_altered'].var())\n",
            ">>> print(df.loc[~events, 'VHL_altered'].var())\n",
            "\n",
            "A very low variance means that the column VHL_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.155. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column YAP1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'YAP1_altered'].var())\n",
            ">>> print(df.loc[~events, 'YAP1_altered'].var())\n",
            "\n",
            "A very low variance means that the column YAP1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.134. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column ZHX2_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'ZHX2_altered'].var())\n",
            ">>> print(df.loc[~events, 'ZHX2_altered'].var())\n",
            "\n",
            "A very low variance means that the column ZHX2_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.110. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MAP2K3_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MAP2K3_altered'].var())\n",
            ">>> print(df.loc[~events, 'MAP2K3_altered'].var())\n",
            "\n",
            "A very low variance means that the column MAP2K3_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.148. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column MYC_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'MYC_altered'].var())\n",
            ">>> print(df.loc[~events, 'MYC_altered'].var())\n",
            "\n",
            "A very low variance means that the column MYC_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.140. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column PDK1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'PDK1_altered'].var())\n",
            ">>> print(df.loc[~events, 'PDK1_altered'].var())\n",
            "\n",
            "A very low variance means that the column PDK1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.111. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/utils/__init__.py:1120: ConvergenceWarning: Column RPS6KB1_altered have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
            "\n",
            ">>> events = df['OS'].astype(bool)\n",
            ">>> print(df.loc[events, 'RPS6KB1_altered'].var())\n",
            ">>> print(df.loc[~events, 'RPS6KB1_altered'].var())\n",
            "\n",
            "A very low variance means that the column RPS6KB1_altered completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression.\n",
            "\n",
            "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/lifelines/fitters/coxph_fitter.py:1607: ConvergenceWarning: Newton-Raphson convergence completed successfully but norm(delta) is still high, 0.131. This may imply non-unique solutions to the maximum likelihood. Perhaps there is collinearity or complete separation in the dataset?\n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for cancer_type in df['cancer_type'].dropna().unique():\n",
        "    df_cancer = df[df['cancer_type'] == cancer_type].copy()\n",
        "    altered_cols = {}\n",
        "\n",
        "    for gene in available_genes:\n",
        "        altered_col = f'{gene}_altered'\n",
        "        altered_cols[altered_col] = df_cancer[gene].apply(lambda x: 1 if pd.notna(x) and str(x).strip().lower() != 'none' else 0)\n",
        "\n",
        "    df_cancer = pd.concat([df_cancer, pd.DataFrame(altered_cols, index=df_cancer.index)], axis=1)\n",
        "\n",
        "    for gene in available_genes:\n",
        "        altered_col = f'{gene}_altered'\n",
        "\n",
        "        if altered_col not in df_cancer.columns:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            cph = CoxPHFitter()\n",
        "            cox_df = df_cancer[[altered_col, 'OS.time', 'OS']].dropna()\n",
        "            if cox_df[altered_col].nunique() < 2:\n",
        "                continue\n",
        "\n",
        "            cph.fit(cox_df, duration_col='OS.time', event_col='OS')\n",
        "            summary = cph.summary.loc[altered_col]\n",
        "\n",
        "\n",
        "            if summary['p'] < 0.05:\n",
        "                results.append({\n",
        "                    'Cancer_Type': cancer_type,\n",
        "                    'Gene': gene,\n",
        "                    'p-value': summary['p'],\n",
        "                    'HR': summary['exp(coef)'],\n",
        "                    'Lower 95% CI': summary['exp(coef) lower 95%'],\n",
        "                    'Upper 95% CI': summary['exp(coef) upper 95%']\n",
        "                })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Model failed for {gene} in {cancer_type} due to: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf22d6aa",
      "metadata": {
        "id": "bf22d6aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f61e54-6267-44d0-d863-5b7090ca8e45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Analysis complete. Results saved to 'cancer_type_specific_altered_genes.csv'\n"
          ]
        }
      ],
      "source": [
        "significant_df = pd.DataFrame(results)\n",
        "significant_df.to_csv('cancer_type_specific_altered_genes.csv', index=False)\n",
        "print(\"✅ Analysis complete. Results saved to 'cancer_type_specific_altered_genes.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After saving significant_df\n",
        "top_genes_per_cancer = (\n",
        "    significant_df\n",
        "    .sort_values(['Cancer_Type', 'p-value'])\n",
        "    .groupby('Cancer_Type')\n",
        "    .head(5)\n",
        ")\n",
        "\n",
        "top_genes_per_cancer.to_csv('top5_genes_per_cancer_type.csv', index=False)\n",
        "print(\"🎯 Top 5 genes per cancer type saved to 'top5_genes_per_cancer_type.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hLS0PupfTg5",
        "outputId": "f6853096-a51e-4709-ea85-2479cab43631"
      },
      "id": "9hLS0PupfTg5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Top 5 genes per cancer type saved to 'top5_genes_per_cancer_type.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('/content/top5_genes_per_cancer_type.csv')\n",
        "\n",
        "# Count how many times each gene appears as a top gene\n",
        "gene_counts = df['Gene'].value_counts().reset_index()\n",
        "gene_counts.columns = ['Gene', 'Count']\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=gene_counts, x='Gene', y='Count', palette='viridis')\n",
        "plt.title('Top Genes by Frequency Across Cancer Types')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "TRJjQ2pNfUrG",
        "outputId": "847879eb-2823-4de1-8251-62a37bb1043d"
      },
      "id": "TRJjQ2pNfUrG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-7eb8e56aae6a>:13: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=gene_counts, x='Gene', y='Count', palette='viridis')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kHEX4mzdgcvm",
        "outputId": "aad58728-031e-4b20-a6b7-75227a2e3058"
      },
      "id": "kHEX4mzdgcvm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Cancer_Type   Gene   p-value        HR  Lower 95% CI  Upper 95% CI\n",
              "0        BLCA  ERBB2  0.003773  0.443094      0.255445      0.768588\n",
              "1        BLCA   KRAS  0.008605  2.280372      1.232929      4.217679\n",
              "2        BLCA  IGF1R  0.021738  2.124439      1.116252      4.043211\n",
              "3        BLCA   MDM4  0.032313  3.504220      1.111572     11.047023\n",
              "4        BLCA  ACACB  0.032925  0.287888      0.091688      0.903924"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8dcd31ee-0bf3-41e9-a73c-6d91fbe824b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cancer_Type</th>\n",
              "      <th>Gene</th>\n",
              "      <th>p-value</th>\n",
              "      <th>HR</th>\n",
              "      <th>Lower 95% CI</th>\n",
              "      <th>Upper 95% CI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BLCA</td>\n",
              "      <td>ERBB2</td>\n",
              "      <td>0.003773</td>\n",
              "      <td>0.443094</td>\n",
              "      <td>0.255445</td>\n",
              "      <td>0.768588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BLCA</td>\n",
              "      <td>KRAS</td>\n",
              "      <td>0.008605</td>\n",
              "      <td>2.280372</td>\n",
              "      <td>1.232929</td>\n",
              "      <td>4.217679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BLCA</td>\n",
              "      <td>IGF1R</td>\n",
              "      <td>0.021738</td>\n",
              "      <td>2.124439</td>\n",
              "      <td>1.116252</td>\n",
              "      <td>4.043211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BLCA</td>\n",
              "      <td>MDM4</td>\n",
              "      <td>0.032313</td>\n",
              "      <td>3.504220</td>\n",
              "      <td>1.111572</td>\n",
              "      <td>11.047023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BLCA</td>\n",
              "      <td>ACACB</td>\n",
              "      <td>0.032925</td>\n",
              "      <td>0.287888</td>\n",
              "      <td>0.091688</td>\n",
              "      <td>0.903924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dcd31ee-0bf3-41e9-a73c-6d91fbe824b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8dcd31ee-0bf3-41e9-a73c-6d91fbe824b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8dcd31ee-0bf3-41e9-a73c-6d91fbe824b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6d4c52d9-5ed0-4754-a420-14e11eebceb5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d4c52d9-5ed0-4754-a420-14e11eebceb5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6d4c52d9-5ed0-4754-a420-14e11eebceb5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 74,\n  \"fields\": [\n    {\n      \"column\": \"Cancer_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"BLCA\",\n          \"SARC\",\n          \"LUSC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gene\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 54,\n        \"samples\": [\n          \"TP53\",\n          \"TSC2\",\n          \"PRKAA2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p-value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015663399854655195,\n        \"min\": 2.8849908257724325e-10,\n        \"max\": 0.0498064263588977,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          0.0329253223563206,\n          0.0035269240112562,\n          0.0048073727294138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.0479279287374865,\n        \"min\": 0.1598379961444497,\n        \"max\": 26.00742829348013,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          0.2878878390253646,\n          0.1814118310352416,\n          7.937261221325745\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lower 95% CI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5816037581443461,\n        \"min\": 0.0504852358807792,\n        \"max\": 2.979447263927285,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          0.0916884307045323,\n          0.0576320502665737,\n          1.880636983735137\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Upper 95% CI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50.22164370871051,\n        \"min\": 0.5060526026223806,\n        \"max\": 307.92667791537315,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          0.9039243797919791,\n          0.5710408060677102,\n          33.49934955040434\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Pivot table for heatmap\n",
        "heatmap_df = df.pivot(index='Cancer_Type', columns='Gene', values='p-value')\n",
        "heatmap_df = -np.log10(heatmap_df)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.heatmap(heatmap_df, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
        "plt.title('-log10(p-value) of Top Genes per Cancer Type')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "kw0zN2dagHw0",
        "outputId": "8ee5c1cb-b638-4912-818c-fdc5f5e019c0"
      },
      "id": "kw0zN2dagHw0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
        "from lifelines.exceptions import ConvergenceError\n",
        "import os\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/sample_data/final_dataset_with_clinical (1).csv')\n",
        "top_genes_df = pd.read_csv('/content/top5_genes_per_cancer_type.csv')\n",
        "\n",
        "# Ensure alteration columns are binary\n",
        "for gene in top_genes_df['Gene'].unique():\n",
        "    col = gene + '_altered'\n",
        "    if col not in df.columns and gene in df.columns:\n",
        "        df[col] = df[gene].apply(lambda x: 1 if pd.notna(x) and str(x).strip().lower() != 'none' else 0)\n",
        "\n",
        "# Create output directory\n",
        "km_output_dir = '/content/sample_data/km_plots'\n",
        "os.makedirs(km_output_dir, exist_ok=True)\n",
        "\n",
        "cox_results = []\n",
        "\n",
        "# Define OS columns\n",
        "time_col = 'OS.time'\n",
        "event_col = 'OS'\n",
        "\n",
        "# Main analysis loop for OS only\n",
        "for _, row in top_genes_df.iterrows():\n",
        "    cancer = row['Cancer_Type']\n",
        "    gene = row['Gene']\n",
        "    altered_col = gene + '_altered'\n",
        "\n",
        "    if altered_col not in df.columns:\n",
        "        continue\n",
        "\n",
        "    df_cancer = df[df['cancer_type'] == cancer].copy()\n",
        "    if df_cancer.empty:\n",
        "        continue\n",
        "\n",
        "    sub_df = df_cancer[[altered_col, time_col, event_col]].dropna()\n",
        "    if sub_df[altered_col].nunique() < 2 or sub_df[event_col].sum() == 0:\n",
        "        continue\n",
        "\n",
        "    # Kaplan-Meier plot\n",
        "    kmf = KaplanMeierFitter()\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    for group in [0, 1]:\n",
        "        mask = sub_df[altered_col] == group\n",
        "        label_name = f\"{gene} {'Altered' if group == 1 else 'Wild-Type'}\"\n",
        "        kmf.fit(sub_df.loc[mask, time_col], sub_df.loc[mask, event_col], label=label_name)\n",
        "        kmf.plot_survival_function(ci_show=True)\n",
        "\n",
        "    plt.title(f\"Overall Survival - {gene} in {cancer}\")\n",
        "    plt.xlabel('Time (days)')\n",
        "    plt.ylabel('Survival Probability')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{km_output_dir}/{cancer}_{gene}_OS_KM.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Cox model\n",
        "    try:\n",
        "        cph = CoxPHFitter()\n",
        "        cph.fit(sub_df[[altered_col, time_col, event_col]], duration_col=time_col, event_col=event_col)\n",
        "        summary = cph.summary.reset_index()\n",
        "        summary['Cancer_Type'] = cancer\n",
        "        summary['Gene'] = gene\n",
        "        summary['Endpoint'] = 'OS'\n",
        "        cox_results.append(summary)\n",
        "    except ConvergenceError:\n",
        "        print(f\"⚠️ Cox model did not converge for {gene} in {cancer}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error for {gene} in {cancer}: {e}\")\n",
        "\n",
        "# Save Cox results\n",
        "if cox_results:\n",
        "    cox_combined = pd.concat(cox_results, ignore_index=True)\n",
        "    cox_combined.to_csv('cox_results_top5_OS_altered.csv', index=False)\n",
        "    print(\"✅ OS-based Cox regression results saved to 'cox_results_top5_OS_altered.csv'\")\n",
        "else:\n",
        "    print(\"⚠️ No valid Cox models were fitted for OS.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSADhG7VfqKn",
        "outputId": "fddc4e30-e785-4864-e3e8-02a76f562914"
      },
      "id": "hSADhG7VfqKn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-479e0411eff2>:8: DtypeWarning: Columns (150) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/sample_data/final_dataset_with_clinical (1).csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OS-based Cox regression results saved to 'cox_results_top5_OS_altered.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('/content/sample_data/km_plots', 'zip', '/content/sample_data/km_plots')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wn5H_w1vf6XU",
        "outputId": "949208df-44b9-4b78-d072-09c65d82997e"
      },
      "id": "wn5H_w1vf6XU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sample_data/km_plots.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/sample_data/km_plots')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "KOWChY8IgBVs",
        "outputId": "ab263205-4503-449d-f010-ce420a27afbd"
      },
      "id": "KOWChY8IgBVs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9d24861c-bb4d-4a88-a0bd-b1da346f8dde\", \"km_plots\", 4096)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load Cox regression results\n",
        "df = pd.read_csv(\"/content/cox_results_top5_OS_altered.csv\")\n",
        "\n",
        "# Convert p-values to numeric, drop invalid\n",
        "df['p'] = pd.to_numeric(df['p'], errors='coerce')\n",
        "df = df.dropna(subset=['p'])\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"cox_summary_plots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 1. Bar plot: Number of significant genes per cancer type\n",
        "significant_counts = df[df['p'] < 0.05].groupby('Cancer_Type').size().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=significant_counts.values, y=significant_counts.index, palette=\"viridis\")\n",
        "plt.xlabel(\"Number of Significant Genes (p < 0.05)\")\n",
        "plt.ylabel(\"Cancer Type\")\n",
        "plt.title(\"Significant Genes per Cancer Type\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{output_dir}/significant_genes_barplot.png\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Heatmap: -log2(p-value) per gene per cancer type (deduplicated)\n",
        "dedup_df = df.groupby(['Gene', 'Cancer_Type'])['p'].min().reset_index()\n",
        "heatmap_data = dedup_df.pivot(index='Gene', columns='Cancer_Type', values='p')\n",
        "heatmap_data = -np.log2(heatmap_data)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(heatmap_data, cmap=\"magma\", annot=False, linewidths=0.5)\n",
        "plt.title(\"-log2(p-value) of Gene Significance Across Cancer Types\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{output_dir}/gene_significance_heatmap.png\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Boxplot: Distribution of exp(coef) by cancer type\n",
        "df['HR'] = np.exp(df['coef'])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='Cancer_Type', y='HR', data=df)\n",
        "plt.axhline(1, color='red', linestyle='--', label='HR = 1')\n",
        "plt.ylabel(\"Hazard Ratio (exp(coef))\")\n",
        "plt.xlabel(\"Cancer Type\")\n",
        "plt.title(\"Distribution of Hazard Ratios by Cancer Type\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{output_dir}/hazard_ratios_boxplot.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0orfkVi8ie9e",
        "outputId": "12bb16cf-c5ad-4e41-98bd-78b0f013d50c"
      },
      "id": "0orfkVi8ie9e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-0428279438a9>:22: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=significant_counts.values, y=significant_counts.index, palette=\"viridis\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Cox regression results file\n",
        "cox_df = pd.read_csv('/content/cox_results_top5_OS_altered.csv')\n",
        "\n",
        "# Calculate summary statistics\n",
        "total_models = len(cox_df)\n",
        "significant_models = (cox_df['p'] < 0.05).sum()\n",
        "highly_significant_models = (cox_df['p'] < 0.01).sum()\n",
        "risky_mutations = (cox_df['exp(coef)'] > 1).sum()\n",
        "protective_mutations = (cox_df['exp(coef)'] < 1).sum()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Total models fitted: {total_models}\")\n",
        "print(f\"Significant models (p < 0.05): {significant_models} ({significant_models / total_models:.1%})\")\n",
        "print(f\"Highly significant models (p < 0.01): {highly_significant_models}\")\n",
        "print(f\"Models with HR > 1 (risky mutations): {risky_mutations}\")\n",
        "print(f\"Models with HR < 1 (protective mutations): {protective_mutations}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq41VTvdnzJM",
        "outputId": "d6febd01-dea0-421d-c1ab-3a576dafeca4"
      },
      "id": "cq41VTvdnzJM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total models fitted: 74\n",
            "Significant models (p < 0.05): 74 (100.0%)\n",
            "Highly significant models (p < 0.01): 36\n",
            "Models with HR > 1 (risky mutations): 60\n",
            "Models with HR < 1 (protective mutations): 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "significant_df = pd.DataFrame(results)\n",
        "significant_df.to_csv('cancer_type_specific_altered_genes.csv', index=False)\n"
      ],
      "metadata": {
        "id": "WbnblAyvplvT"
      },
      "id": "WbnblAyvplvT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"cancer_type_specific_altered_genes.csv\")\n",
        "df.sort_values(\"p-value\").head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "PK_ngGk3uhyw",
        "outputId": "e414436d-514d-4842-eb21-16a47575b61d"
      },
      "id": "PK_ngGk3uhyw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Cancer_Type   Gene       p-value        HR  Lower 95% CI  Upper 95% CI\n",
              "7           LGG   EGFR  2.884991e-10  4.875481      2.979447      7.978095\n",
              "96         UCEC   TP53  4.525662e-05  2.442064      1.590132      3.750430\n",
              "10          LGG   TP53  8.153601e-05  0.459096      0.311680      0.676234\n",
              "93         UCEC   PTEN  1.046478e-04  0.433511      0.284192      0.661286\n",
              "55          GBM   TP53  2.751832e-04  0.582133      0.434926      0.779166\n",
              "48         LUAD   DVL3  6.238769e-04  3.255371      1.655473      6.401458\n",
              "107        COAD  LATS2  7.728703e-04  3.289258      1.643131      6.584513\n",
              "33         BRCA   SOX9  1.037893e-03  5.386850      1.969392     14.734574\n",
              "28         BRCA  ERBB2  1.039137e-03  4.052895      1.756156      9.353359\n",
              "76         UCEC    ATM  1.144756e-03  0.251216      0.109268      0.577567"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0a57d07-5771-4896-9e64-db1ab18b523e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cancer_Type</th>\n",
              "      <th>Gene</th>\n",
              "      <th>p-value</th>\n",
              "      <th>HR</th>\n",
              "      <th>Lower 95% CI</th>\n",
              "      <th>Upper 95% CI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LGG</td>\n",
              "      <td>EGFR</td>\n",
              "      <td>2.884991e-10</td>\n",
              "      <td>4.875481</td>\n",
              "      <td>2.979447</td>\n",
              "      <td>7.978095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>UCEC</td>\n",
              "      <td>TP53</td>\n",
              "      <td>4.525662e-05</td>\n",
              "      <td>2.442064</td>\n",
              "      <td>1.590132</td>\n",
              "      <td>3.750430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LGG</td>\n",
              "      <td>TP53</td>\n",
              "      <td>8.153601e-05</td>\n",
              "      <td>0.459096</td>\n",
              "      <td>0.311680</td>\n",
              "      <td>0.676234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>UCEC</td>\n",
              "      <td>PTEN</td>\n",
              "      <td>1.046478e-04</td>\n",
              "      <td>0.433511</td>\n",
              "      <td>0.284192</td>\n",
              "      <td>0.661286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>GBM</td>\n",
              "      <td>TP53</td>\n",
              "      <td>2.751832e-04</td>\n",
              "      <td>0.582133</td>\n",
              "      <td>0.434926</td>\n",
              "      <td>0.779166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>LUAD</td>\n",
              "      <td>DVL3</td>\n",
              "      <td>6.238769e-04</td>\n",
              "      <td>3.255371</td>\n",
              "      <td>1.655473</td>\n",
              "      <td>6.401458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>COAD</td>\n",
              "      <td>LATS2</td>\n",
              "      <td>7.728703e-04</td>\n",
              "      <td>3.289258</td>\n",
              "      <td>1.643131</td>\n",
              "      <td>6.584513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>BRCA</td>\n",
              "      <td>SOX9</td>\n",
              "      <td>1.037893e-03</td>\n",
              "      <td>5.386850</td>\n",
              "      <td>1.969392</td>\n",
              "      <td>14.734574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>BRCA</td>\n",
              "      <td>ERBB2</td>\n",
              "      <td>1.039137e-03</td>\n",
              "      <td>4.052895</td>\n",
              "      <td>1.756156</td>\n",
              "      <td>9.353359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>UCEC</td>\n",
              "      <td>ATM</td>\n",
              "      <td>1.144756e-03</td>\n",
              "      <td>0.251216</td>\n",
              "      <td>0.109268</td>\n",
              "      <td>0.577567</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0a57d07-5771-4896-9e64-db1ab18b523e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f0a57d07-5771-4896-9e64-db1ab18b523e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f0a57d07-5771-4896-9e64-db1ab18b523e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0440ba5b-6532-4de4-90c3-8e0aeff24551\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0440ba5b-6532-4de4-90c3-8e0aeff24551')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0440ba5b-6532-4de4-90c3-8e0aeff24551 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Cancer_Type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"LGG\",\n          \"UCEC\",\n          \"BRCA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gene\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"TP53\",\n          \"SOX9\",\n          \"EGFR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p-value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00046220421854786163,\n        \"min\": 2.8849908257724325e-10,\n        \"max\": 0.0011447557080105,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0010391371830046,\n          4.525662029705304e-05,\n          0.0006238769126058\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.965140507856879,\n        \"min\": 0.2512160748792075,\n        \"max\": 5.386849874770696,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          4.052894972197335,\n          2.442064088509079,\n          3.2553708597739006\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lower 95% CI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9412010845546243,\n        \"min\": 0.1092678175688264,\n        \"max\": 2.979447263927285,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.7561560023610634,\n          1.5901316342828766,\n          1.6554728893813042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Upper 95% CI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.752632677665338,\n        \"min\": 0.5775672808506834,\n        \"max\": 14.734574249007927,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9.35335906011685,\n          3.7504297655679295,\n          6.4014575549018025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}